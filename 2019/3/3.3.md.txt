#  如何实现高可用

首先看一下最近一年内大规模的云故障（从近到远）：

  +  https://www.infoq.cn/article/39ZaKJCx9-9ITs8vJw2w
  
  ![阿里云](https://static001.geekbang.org/resource/image/f7/ed/f76dca82d4f8778285ba60b0d89eb9ed.jpg)
  
  + [2018 年十大云宕机事故盘点：主流无一幸免！](https://www.infoq.cn/article/4pSNXHT4PuI4T*L8g1Sk)
  
  总体统计： 
  [根据笔者统计，仅去年一年，全球主流云计算厂商就曾发生数十起宕机事故，原因更是五花八门，
  谷歌云曾因自动化失效导致宕机、AWS 曾因数据中心出现硬件问题导致宕机、
  微软 Azure 爱尔兰数据中心曾因高温和打雷陷入宕机、腾讯云因运营和硬盘故障陷入宕机…](https://www.infoq.cn/article/39ZaKJCx9-9ITs8vJw2w)
  
  从这一些统计数据可以看到，公有云在提供了基础设施的快速获取和释放，但是和过去的托管机房一样，故障是不可避免的；但是
  现在的客户对于可用性的要求是10年前无法想象的，所有的系统，无论是初创公司还是业界领先，必须都是高可用的，否则
  就会流失客户，导致投资人失去信心，甚至会导致产品失败--最终导致公司的失败。
  
   总之，现在系统的高可用已经不再是一句口号，一种宣传而是实实在在的需要达到的目标。 
   问题来了， 如何真正实现高可用的服务（即如何实现高可用架构）？
  
  首先我们把目光从IT系统拿开:
  
  最早做高可用设计的典范：
   
    +组织类：苏联军队的隐形部队，算是第一次组织上的高可用配置，后面只要是正常的企业都会对职能职位做同样的处理。
    +交通类：铁路等交通的高可用主要是通过 多种交通方式： 最典型的进入西藏的公路有多条的同时，还有铁路和飞机。
    
  等等...
  
  现在返回到词语定义： 参考wiki 
  
   [高可用](https://zh.wikipedia.org/wiki/%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7) 
   
  [High availability](https://en.wikipedia.org/wiki/High_availability)   
  
  高可用性（HA）是系统的一个特征，旨在确保达到一致的操作性能水平，通常是正常运行时间，高于正常时间段。
  
  现代化导致对这些系统的依赖性增加。例如，医院和数据中心需要其系统的高可用性来执行日常日常活动。可用性是指用户社区获取服务或商品，访问系统，是否提交新工作，更新或更改现有工作或收集以前工作结果的能力。如果用户无法访问系统，则从用户的角度来看，它是不可用的。[1]通常，术语停机时间用于指系统不可用的时段。
  
  而如何在IT系统实现高可用？ 首先就要通过FMEA等方法分析，系统不可用的原因。
  
  [不可用的原因](https://en.wikipedia.org/wiki/High_availability#cite_note-15)
  
  2010年学术可用性专家的一项调查分析了企业IT系统不可用的原因。所有原因均指未遵循以下每个方面的最佳做法（按重要性排序）：[13]
  
  + 监控相关组件
  + 要求和采购
  + 操作
  + 避免网络故障
  + 避免内部应用程序故障
  + 避免失败的外部服务
  + 物理环境
  + 网络冗余
  + 备份技术方案
  + 备份的处理解决方案
  + 物理位置
  + 基础设施冗余
  + 存储架构冗余

  我们首先看一下现在使用了公有云单一部署的情况 可以解决什么问题？ 
   + 监控相关组件
   + 要求和采购
   + 操作
   + 避免网络故障
   + 避免失败的外部服务
   + 物理环境
   + 网络冗余
   + 备份技术方案
   + 备份的处理解决方案
   + 基础设施冗余
   + 存储架构冗余
  
  再看一下现在使用了公有云分布式系统部署（单一Zone）的情况
   + 监控相关组件
   + 要求和采购
   + 操作
   + 避免网络故障
   + 避免内部应用程序故障
   + 避免失败的外部服务
   + 物理环境
   + 网络冗余
   + 备份技术方案
   + 备份的处理解决方案
   + 基础设施冗余
   + 存储架构冗余
  
  最后再来看现在公有云上高可用做得很好，并且完全开源的Netflix是做到了哪些：
  
   + 监控相关组件
   + 要求和采购
   + 操作
   + 避免网络故障
   + 避免内部应用程序故障
   + 避免失败的外部服务
   + 物理环境
   + 网络冗余
   + 备份技术方案
   + 备份的处理解决方案
   + 物理位置
   + 基础设施冗余
   + 存储架构冗余
  
  但是Netflix 是如何做到的？
  
  + [来自Netflix的10条高可用架构建议](https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&mid=2247488976&idx=1&sn=da3a8e8d8eaf9eaf03e154b08153752d&chksm=eba4164ddcd39f5ba7b579645103d385be06717389c3da47de5f1d4eb1b23eff6290ad2e92d4&scene=27#wechat_redirect)
  + [在一个成熟的分布式系统中如何下手做高可用？](https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&mid=2247490239&idx=1&sn=33fe523912bfd2d09dd4f97053bbc97b&chksm=e8d7e57ddfa06c6b9a9202de049606cf5b8029d79ca8c756f66155ebc82bc9c6f912e4ea7b57&scene=27#wechat_redirect)
  + [如何设计高可用的微服务架构？](https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&mid=2650997771&idx=1&sn=63da21da52ac709d90080ff4837fb474&chksm=bdbefc588ac9754ef8dbc059ed9cbe43f03aa32828ba60f85869f2591a107eea4162805457f6&scene=27#wechat_redirect)
 
 当然，这个时候必须拿出一本互联网架构方面的经典书籍： 
 
  [架构即未来:现代企业可扩展的Web架构、流程和组织(原书第2版) ](https://www.amazon.cn/dp/B01DXW29IM)
  里面最重要的一句话：  
  
     对于产品的架构，不论是成功的处理了海量交易，还是悲惨地在消费者的压力下奔溃，人都是要负全部责任。
  
  第二句话：
          
          斗众如斗寡，形名是也
        
          指挥大部队作战如同指挥小部队作战，关键在于通讯要畅通。
  如何做到第二句话：
          
          两张披萨饼团队规则：任何一个团队的规模不能大过两张披萨饼能所喂饱的人数。
  
  
  ## 一切的流程，架构等等具体的实现和运作这个系统的都是人，没有合适的人员，良好的管理，优秀的文化，你是无论如何也不能在合适（最优）的成本下实现高可用可扩展的系统。
  
  **【参考】**
  主要参考对象 NetFlix
  + http://developer.51cto.com/art/201710/554091.htm
  + https://36kr.com/p/5095320.html
  + https://coolshell.cn/articles/17459.html
  + 要实现AWS上计算资源的跨可用区的架构，就可以结合如上ELB + Auto-Scaling + EC2的模式，非常直接和高效地实现整个业务的跨可用区高可用设计
 
  ![要实现AWS上计算资源的跨可用区的架构，就可以结合如上ELB + Auto-Scaling + EC2的模式，非常直接和高效地实现整个业务的跨可用区高可用设计](http://blog.fit2cloud.com/images/2016-08-14/aws-web-hosting.png)
  
  
  [关于高可用的系统](https://coolshell.cn/articles/17459.html)
  
  真正决定高可用系统的本质原因
  
  从上面这些会影响高可用的SLA的因素，你看到了什么？如果你还是只看到了技术方面或是软件设计的东西，那么你只看到了冰山一角。我们再仔细想一想，那个5个9的SLA在一年内只能是5分钟的不可用时间，5分钟啊，如果按一年只出1次故障，你也得在五分钟内恢复故障，让我们想想，这意味着什么？
  
  如果你没有一套科学的牛逼的软件工程的管理，没有牛逼先进的自动化的运维工具，没有技术能力很牛逼的工程师团队，怎么可能出现高可用的系统啊。
  
  是的，要干出高可用的系统，这TMD就是一套严谨科学的工程管理，其中包括但不限于了：
  
 +  软件的设计、编码、测试、上线和软件配置管理的水平
 +  工程师的人员技能水平
 +  运维的管理和技术水平
 + 数据中心的运营管理水平
 +  依赖于第三方服务的管理水平
 
  深层交的东西则是——对工程这门科学的尊重：
  
 +  对待技术的态度
 + 一个公司的工程文化
 + 领导者对工程的尊重
 
  所以，以后有人在你面前提高可用，你要看的不是他的技术设计，而还要看看他们的工程能力，看看他们公司是否真正的尊重工程这门科学。
  
  其它
  
  有好些非技术甚至技术人员和我说过，做个APP做个网站，不就是找几个码农过来写写代码嘛。等系统不可用的时候，他们才会明白，要找技术能力比较强的人，但是，就算你和他们讲一万遍道理，他们也很难会明白写代码怎么就是一种工程了，而工程怎么就成了一门科学了。其实，很多做技术的人都不明白这个道理。
  
  
  包括很多技术人员也永远不会理解，为什么要做好多像Code Review、自动化运维、自动化测试、持续集成之类这样很无聊的东西。就像我在《从Code Review 谈如何做技术》中提到的，阿里很多的工程师，架构师/专家，甚至资深架构师都没有这个意识，当然，这不怪他们，因为经历决定思维方式，他们的经历的是民用级的系统，做的都是堆功能的工作，的确不需要。
  
  
  看完这些，最后让我们都扪心自问一下，你还敢说你的系统是高可用的了么？ ;-)